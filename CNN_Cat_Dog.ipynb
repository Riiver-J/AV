{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1. Task 설정하기"
      ],
      "metadata": {
        "id": "Mp9brFOiV94C"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EMefrVPCg-60"
      },
      "source": [
        "## 라이브러리 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCV30xyVhFbE"
      },
      "source": [
        "import tensorflow as tf\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "FIleuCAjoFD8",
        "outputId": "f34610f1-49da-452c-daff-25a73d383e9c"
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.9.2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, Conv2D, Dense, Flatten, Dropout,\\\n",
        "GlobalMaxPooling2D, MaxPooling2D, BatchNormalization\n",
        "from tensorflow.keras.models import Model"
      ],
      "metadata": {
        "id": "7isA78VmRFdF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2. 데이터셋 준비하기\n"
      ],
      "metadata": {
        "id": "P3QbEt4BWQA1"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxQxCBWyoGPE"
      },
      "source": [
        "## Step 2-1 데이터 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZyv3y6_rO3G",
        "outputId": "76330638-ef46-4704-885a-97f1fc347e55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QGpvyUlUxpRb",
        "outputId": "a74a1d91-bc47-4852-87dd-8899b33d9565"
      },
      "source": [
        "!ls "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drive  gdrive  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "keagRiNx1JxO",
        "outputId": "4bbcc7c2-c831-40d4-8446-88c7e85d076b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "!ls '/content/gdrive/MyDrive/catdog'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "dataset  desktop.ini  Practice_CatDog.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvE-heJNo3GG"
      },
      "source": [
        "## Step 2-2. 데이터 전처리 하기.\n",
        "### 훈련데이터 전처리 하기: 스케일링 및 데이터 증강\n",
        " - 이미지 데이터를 255로 나누어 0~1 사이의 값으로 맞추어 준다\n",
        " - 데이터를 증강한다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0koUcJMJpEBD",
        "outputId": "91c2a699-8352-4067-e849-ee87a05c4eb5"
      },
      "source": [
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "training_set = train_datagen.flow_from_directory('/content/gdrive/MyDrive/catdog/dataset/training_set',\n",
        "                                                 target_size = (64, 64),\n",
        "                                                 batch_size = 32,\n",
        "                                                 class_mode = 'binary') #_directory:라벨이 나눠져서 폴더별로있는경우, 바로 구분해서 끌고옴 // targetsize:알아서downsizing해줌 // 여기서는 개or고양이이므로 binary Q.아니라면?파라메터조정을 어떻게해야되는지 알아보기"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 6803 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrCMmGw9pHys"
      },
      "source": [
        "### 테스트데이터 전처리 하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SH4WzfOhpKc3",
        "outputId": "a657fe26-a31e-4736-877f-aba27d6ca98b"
      },
      "source": [
        "test_datagen = ImageDataGenerator(rescale = 1./255) #nomalize\n",
        "test_set = test_datagen.flow_from_directory('/content/gdrive/MyDrive/catdog/dataset/test_set',\n",
        "                                            target_size = (64, 64),\n",
        "                                            batch_size = 32,\n",
        "                                            class_mode = 'binary')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1184 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "af8O4l90gk7B"
      },
      "source": [
        "# Step 3. 모델 훈련하기\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ces1gXY2lmoX"
      },
      "source": [
        "## Step 3-1. 모델 설계하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u5YJj_XMl5LF"
      },
      "source": [
        "### Stage 1. 특성 추출"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XPzPrMckl-hV"
      },
      "source": [
        "cnn = tf.keras.models.Sequential()\n",
        "\n",
        "# 컨볼루션 1층\n",
        "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[64, 64, 3]))\n",
        "\n",
        "\n",
        "# 컨볼루션-풀링 2층\n",
        "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmiEuvTunKfk"
      },
      "source": [
        "Flattening"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6AZeOGCvnNZn"
      },
      "source": [
        "cnn.add(tf.keras.layers.Flatten())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAoSECOm203v"
      },
      "source": [
        "### Stage 2. - Full Connection(ANN)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GtmUlLd26Nq"
      },
      "source": [
        "#ANN의 입력층\n",
        "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))\n",
        "#ANN의 출력층\n",
        "cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6XkI90snSDl"
      },
      "source": [
        "## Step 3-2 모델 컴파일"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NALksrNQpUlJ"
      },
      "source": [
        "cnn.compile(optimizer = 'adam', \n",
        "            loss = 'binary_crossentropy', \n",
        "            metrics = ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehS-v3MIpX2h"
      },
      "source": [
        "## Step 3-3 모델 훈련"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XUj1W4PJptta",
        "outputId": "e2945387-8309-484f-f960-addabcc8a499"
      },
      "source": [
        "cnn.fit(x = training_set,\n",
        "        validation_data = test_set,\n",
        "        epochs = 25)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "213/213 [==============================] - 939s 4s/step - loss: 0.7225 - accuracy: 0.6241 - val_loss: 0.7820 - val_accuracy: 0.4721\n",
            "Epoch 2/25\n",
            "213/213 [==============================] - 38s 178ms/step - loss: 0.6017 - accuracy: 0.6919 - val_loss: 0.6309 - val_accuracy: 0.6208\n",
            "Epoch 3/25\n",
            "213/213 [==============================] - 37s 175ms/step - loss: 0.5700 - accuracy: 0.7106 - val_loss: 0.9608 - val_accuracy: 0.6039\n",
            "Epoch 4/25\n",
            "213/213 [==============================] - 37s 174ms/step - loss: 0.5369 - accuracy: 0.7344 - val_loss: 0.5371 - val_accuracy: 0.7500\n",
            "Epoch 5/25\n",
            "213/213 [==============================] - 38s 176ms/step - loss: 0.5050 - accuracy: 0.7575 - val_loss: 0.5349 - val_accuracy: 0.7373\n",
            "Epoch 6/25\n",
            "213/213 [==============================] - 37s 175ms/step - loss: 0.4785 - accuracy: 0.7729 - val_loss: 0.4098 - val_accuracy: 0.8209\n",
            "Epoch 7/25\n",
            "213/213 [==============================] - 40s 188ms/step - loss: 0.4632 - accuracy: 0.7820 - val_loss: 0.5736 - val_accuracy: 0.7204\n",
            "Epoch 8/25\n",
            "213/213 [==============================] - 37s 174ms/step - loss: 0.4390 - accuracy: 0.7951 - val_loss: 0.5156 - val_accuracy: 0.7804\n",
            "Epoch 9/25\n",
            "213/213 [==============================] - 37s 174ms/step - loss: 0.4156 - accuracy: 0.8121 - val_loss: 0.5414 - val_accuracy: 0.7863\n",
            "Epoch 10/25\n",
            "213/213 [==============================] - 38s 177ms/step - loss: 0.4015 - accuracy: 0.8188 - val_loss: 0.4610 - val_accuracy: 0.8117\n",
            "Epoch 11/25\n",
            "213/213 [==============================] - 37s 174ms/step - loss: 0.3871 - accuracy: 0.8254 - val_loss: 0.4143 - val_accuracy: 0.8285\n",
            "Epoch 12/25\n",
            "213/213 [==============================] - 37s 174ms/step - loss: 0.3694 - accuracy: 0.8329 - val_loss: 0.5850 - val_accuracy: 0.7736\n",
            "Epoch 13/25\n",
            "213/213 [==============================] - 37s 174ms/step - loss: 0.3474 - accuracy: 0.8445 - val_loss: 0.4332 - val_accuracy: 0.8345\n",
            "Epoch 14/25\n",
            "213/213 [==============================] - 37s 173ms/step - loss: 0.3469 - accuracy: 0.8449 - val_loss: 0.4764 - val_accuracy: 0.8176\n",
            "Epoch 15/25\n",
            "213/213 [==============================] - 40s 186ms/step - loss: 0.3228 - accuracy: 0.8602 - val_loss: 0.5970 - val_accuracy: 0.7703\n",
            "Epoch 16/25\n",
            "213/213 [==============================] - 37s 174ms/step - loss: 0.3074 - accuracy: 0.8724 - val_loss: 0.7082 - val_accuracy: 0.7137\n",
            "Epoch 17/25\n",
            "213/213 [==============================] - 37s 173ms/step - loss: 0.2953 - accuracy: 0.8761 - val_loss: 0.4709 - val_accuracy: 0.8184\n",
            "Epoch 18/25\n",
            "213/213 [==============================] - 37s 173ms/step - loss: 0.2831 - accuracy: 0.8834 - val_loss: 0.5579 - val_accuracy: 0.8032\n",
            "Epoch 19/25\n",
            "213/213 [==============================] - 37s 175ms/step - loss: 0.2661 - accuracy: 0.8908 - val_loss: 0.7324 - val_accuracy: 0.7492\n",
            "Epoch 20/25\n",
            "213/213 [==============================] - 37s 175ms/step - loss: 0.2513 - accuracy: 0.8977 - val_loss: 0.5735 - val_accuracy: 0.7922\n",
            "Epoch 21/25\n",
            "213/213 [==============================] - 37s 175ms/step - loss: 0.2287 - accuracy: 0.9061 - val_loss: 0.4965 - val_accuracy: 0.8412\n",
            "Epoch 22/25\n",
            "213/213 [==============================] - 37s 174ms/step - loss: 0.2333 - accuracy: 0.9045 - val_loss: 0.6347 - val_accuracy: 0.7914\n",
            "Epoch 23/25\n",
            "213/213 [==============================] - 40s 187ms/step - loss: 0.2211 - accuracy: 0.9099 - val_loss: 0.7031 - val_accuracy: 0.7880\n",
            "Epoch 24/25\n",
            "213/213 [==============================] - 36s 171ms/step - loss: 0.1895 - accuracy: 0.9233 - val_loss: 0.7450 - val_accuracy: 0.7610\n",
            "Epoch 25/25\n",
            "213/213 [==============================] - 37s 172ms/step - loss: 0.1846 - accuracy: 0.9242 - val_loss: 0.8237 - val_accuracy: 0.7686\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f83c059b520>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3PZasO0006Z"
      },
      "source": [
        "## Step 5. 모델 활용하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "gsSiWEJY1BPB",
        "outputId": "b380cd4e-afda-444b-b3cc-f7cd5047a12e"
      },
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "test_image = image.load_img('/content/gdrive/MyDrive/catdog/dataset/single_prediction/cat_dog_3.png', target_size = (64, 64))\n",
        "test_image = image.img_to_array(test_image)\n",
        "test_image = np.expand_dims(test_image, axis = 0)\n",
        "result = cnn.predict(test_image)\n",
        "training_set.class_indices\n",
        "if result[0][0] == 1:\n",
        "    prediction = 'dog'\n",
        "else:\n",
        "    prediction = 'cat'\n",
        "\n",
        "print(result)\n",
        "print(prediction)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-ce00b334cd6b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtest_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/gdrive/MyDrive/catdog/dataset/single_prediction/cat_dog_3.png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtest_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtest_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'keras.preprocessing.image' has no attribute 'load_img'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " ### 학습한 모델 저장하기"
      ],
      "metadata": {
        "id": "4qIp_hiyeGYy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 기본폴더에 모델을 저장하면 데이터가 사라진다.\n",
        "# 원하는 경로를 입력한 뒤 모델을 저장해 준다.\n",
        "\n",
        "# 작업폴더 변경\n",
        "%cd '/content/gdrive/MyDrive'\n",
        "# 훈련한 cnn 모델을 \"cat_dog.h5\" 이라는 이름으로 저장해 준다.\n",
        "cnn.save(\"cat_dog.h5\")\n",
        "# 저장이 제대로 되었는지 확인한다.\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0wpt96wAIP9o",
        "outputId": "a201d213-9695-41c5-aec5-bee3b285441f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive\n",
            " ㄱㅇ\n",
            "'18차시_CNN_CIFAR_Improved.ipynb의 사본'\n",
            "'제목 없는 문서 (1).gdoc'\n",
            " 1.gdoc\n",
            " 1.jpg\n",
            "'20차시_LSTM_imdb_lstm.ipynb의 사본'\n",
            "'21차시_LSTM_Stock_Returns.ipynb의 사본'\n",
            " 2.gdoc\n",
            "'인공지능활용분석2급_실기_시험_소스코드_수강생제공용.ipynb의 사본'\n",
            " 2.jpg\n",
            "'2._인공지능 능력자 with Python_코딩기반_전처리_시각화_인공지능합본.pdf'\n",
            " 3.jpg\n",
            " 4.jpg\n",
            " 5.jpg\n",
            " 6.jpg\n",
            " 7.jpg\n",
            " CASE_NIKE.pdf\n",
            " catdog\n",
            "'cat dog'\n",
            " cat_dog.h5\n",
            "'Colab Notebooks'\n",
            " DevKurly\n",
            "'제목 없는 문서.gdoc'\n",
            "'제목 없는 문서의 번역된 사본.gdoc'\n",
            " 이력서.gdoc\n",
            "'제목 없는 스프레드시트.gsheet'\n",
            "'Numpy Stack.'\n",
            "'ONLYFRESH (1).gslides'\n",
            "'OnlyFresh-2 (1).pdf'\n",
            " OnlyFresh-2.pdf\n",
            " ONLYFRESH.gslides\n",
            "'Team DevKurly 화면정의서 (1).gdoc'\n",
            "'Team DevKurly 화면정의서.gdoc'\n",
            " Untitled\n",
            " Untitled0.ipynb\n",
            " walmart-china.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 저장해둔 모델로 분석하기"
      ],
      "metadata": {
        "id": "2LhD93cddvvL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')\n",
        "%cd '/content/gdrive/MyDrive'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lPGkjAoeqnpv",
        "outputId": "5fc3f09a-7abc-478f-dc9e-8f7548ca563f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n",
            "/content/gdrive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "from keras.models import load_model\n",
        "\n",
        "# 모델이 저장되어있는 폴더의 경로르 입력해 준다.\n",
        "%cd '/content/gdrive/MyDrive'\n",
        "#저장된 모델을 불러온다\n",
        "cnn = load_model('cat_dog.h5')\n",
        "\n",
        "#분석할 이미지의 경로를 입력하고 불러온다.\n",
        "test_image = image.load_img('/content/gdrive/MyDrive/catdog/dataset/single_prediction/cat_or_dog_1.jpg',\n",
        "                            target_size = (64, 64))\n",
        "#불러온 이미지를 어레이 데이터로 바꾼다\n",
        "test_image = image.img_to_array(test_image)\n",
        "#테스트 이미지의 차원을 확장한다.\n",
        "test_image = np.expand_dims(test_image, axis = 0)\n",
        "# 학습한 모델로 예측한 결과물을 result 변수에 저장해 준다.\n",
        "result = cnn.predict(test_image)\n",
        "\n",
        "# training_set.class_indices\n",
        "if result[0][0] == 0:\n",
        "    prediction = 'cat'\n",
        "else:\n",
        "    prediction = 'dog'\n",
        "\n",
        "print(result)\n",
        "print(prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "nHZg0G6xIny3",
        "outputId": "5338b953-bffb-49f0-9345-738666de83d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-860e6af76880>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#분석할 이미지의 경로를 입력하고 불러온다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m test_image = image.load_img('/content/gdrive/MyDrive/catdog/dataset/single_prediction/cat_or_dog_1.jpg',\n\u001b[0m\u001b[1;32m     12\u001b[0m                             target_size = (64, 64))\n\u001b[1;32m     13\u001b[0m \u001b[0;31m#불러온 이미지를 어레이 데이터로 바꾼다\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'keras.preprocessing.image' has no attribute 'load_img'"
          ]
        }
      ]
    }
  ]
}